{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    @abc.abstractmethod\n",
    "    def optimize(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentOptimizer(Optimizer):\n",
    "    def __init__(self, learning_rate: float = 0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def optimize(self, val, grad):\n",
    "        return val - self.learning_rate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, x):\n",
    "        pass\n",
    "    @abc.abstractmethod\n",
    "    def gradient(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(ActivationFunction):\n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        sig = self.__call(x)\n",
    "        return sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(ActivationFunction):\n",
    "    def __call__(self, x):\n",
    "        return np.where(x >= 0, x, 0)\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return np.where(x >= 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initializer(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, var):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformInitializer(Initializer):\n",
    "    def __call__(self, mean, var, shape):\n",
    "        stddev = np.sqrt(var)\n",
    "        lim = np.sqrt(3) * stddev\n",
    "        \n",
    "        return np.random.uniform(-lim, lim, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def set_optimizer(self, optimizer):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def forward_pass(self, X):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def backward_pass(self, X):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def output_shape(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, n_units, input_shape=None):\n",
    "        self.n_units = n_units\n",
    "    \n",
    "    def set_activation(self, activation):\n",
    "        if not isinstance(activation, Activation):\n",
    "            raise Exception('The activation object provided is not an instance of Activation class.')\n",
    "        \n",
    "        self.activation = activation\n",
    "    \n",
    "    def initialize(self, initializer):\n",
    "        if not isinstance(initializer, Initializer):\n",
    "            raise Exception('The initializer object provided is not an instance of Initializer class.')\n",
    "        \n",
    "        self.initializer = initializer\n",
    "        \n",
    "        self.W = self.initializer(mean=0, var=1/units, shape=(units, input_shape[0]))\n",
    "        self.b = self.initializer(mean=0, var=1/units, shape=(units, 1))\n",
    "    \n",
    "    def set_optimizer(self, optimizer):\n",
    "        \n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise Exception('The optimizer object provided is not an instance of Optimizer class.')\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        return self.W.dot(X) + b\n",
    "    \n",
    "    def backward_pass(self, cum_grad):\n",
    "        grad_W = cum_grad * X.T\n",
    "        grad_b = np.sum(cum_grad, axis=1)\n",
    "        \n",
    "        self.optimizer.optimize(grad_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
